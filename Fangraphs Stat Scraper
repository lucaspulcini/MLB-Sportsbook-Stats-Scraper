import os
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# URLs for fangraphs L30 pitcher and team stats.
URLS = {
    'pitcher_stats_home': "https://www.fangraphs.com/leaders/splits-leaderboards?splitArr=9&splitArrPitch=&position=P&autoPt=false&splitTeams=false&statType=player&statgroup=2&startDate=2024-8-4&endDate=2024-9-2&players=&filter=&groupBy=season&wxTemperature=&wxPressure=&wxAirDensity=&wxElevation=&wxWindSpeed=&sort=23,1&pageitems=2000000000&pg=0",
    'pitcher_stats_away': "https://www.fangraphs.com/leaders/splits-leaderboards?splitArr=10&splitArrPitch=&position=P&autoPt=false&splitTeams=false&statType=player&statgroup=2&startDate=2024-8-4&endDate=2024-9-2&players=&filter=&groupBy=season&wxTemperature=&wxPressure=&wxAirDensity=&wxElevation=&wxWindSpeed=&sort=23,1&pageitems=2000000000&pg=0",
    'team_stats_home_vs_LHP': "https://www.fangraphs.com/leaders/splits-leaderboards?splitArr=1,7&splitArrPitch=&position=B&autoPt=false&splitTeams=false&statType=team&statgroup=2&startDate=2024-8-4&endDate=2024-9-2&players=&filter=&groupBy=season&wxTemperature=&wxPressure=&wxAirDensity=&wxElevation=&wxWindSpeed=&sort=9,1&pageitems=2000000000&pg=0",
    'team_stats_home_vs_RHP': "https://www.fangraphs.com/leaders/splits-leaderboards?splitArr=2,7&splitArrPitch=&position=B&autoPt=false&splitTeams=false&statType=team&statgroup=2&startDate=2024-8-4&endDate=2024-9-2&players=&filter=&groupBy=season&wxTemperature=&wxPressure=&wxAirDensity=&wxElevation=&wxWindSpeed=&sort=9,1&pageitems=2000000000&pg=0",
    'team_stats_away_vs_LHP': "https://www.fangraphs.com/leaders/splits-leaderboards?splitArr=1,8&splitArrPitch=&position=B&autoPt=false&splitTeams=false&statType=team&statgroup=2&startDate=2024-8-4&endDate=2024-9-2&players=&filter=&groupBy=season&wxTemperature=&wxPressure=&wxAirDensity=&wxElevation=&wxWindSpeed=&sort=9,1&pageitems=2000000000&pg=0",
    'team_stats_away_vs_RHP': "https://www.fangraphs.com/leaders/splits-leaderboards?splitArr=2,8&splitArrPitch=&position=B&autoPt=false&splitTeams=false&statType=team&statgroup=2&startDate=2024-8-4&endDate=2024-9-2&players=&filter=&groupBy=season&wxTemperature=&wxPressure=&wxAirDensity=&wxElevation=&wxWindSpeed=&sort=9,1&pageitems=2000000000&pg=0"
}

# Headers to look for in the fangraphs table.
HEADERS = {
    'pitcher_headers': ['Name', 'Tm', 'K%', 'BB%', 'WHIP', 'FIP'],
    'team_headers': ['Tm', 'BB%', 'K%', 'SLG', 'OPS', 'wRC+']
}

def setup_webdriver():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--disable-gpu')
    return webdriver.Chrome(options=options)

def scrape_fangraphs_stats(url, target_headers):
    driver = setup_webdriver()
    
    try:
        driver.get(url)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, 'data-grid-wrapper'))
        )

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        table = soup.find('div', class_='table-scroll')

        headers = [th.text.strip() for th in table.find('thead').find_all('th')]
        indices = [i for i, h in enumerate(headers) if h in target_headers]
        rows = table.find('tbody').find_all('tr')

        data_rows = []
        for row in rows:
            columns = [td.text.strip() for td in row.find_all('td')]
            filtered_columns = [columns[i] for i in indices]
            data_rows.append(filtered_columns)

        df = pd.DataFrame(data_rows, columns=[headers[i] for i in indices])

        return df

    finally:
        driver.quit()

def save_dataframes_to_tsv(data_frames, folder_name="TSV Files"):
    project_path = os.path.dirname(os.path.abspath(__file__))

    folder_path = os.path.join(project_path, folder_name)
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)

    for category, df in data_frames.items():
        tsv_filename = f'{category}.tsv'
        save_path = os.path.join(folder_path, tsv_filename)
        df.to_csv(save_path, sep='\t', index=False)
        print(f"Saved {category} data to {save_path}")

def main():
    data_frames = {}
    for category, url in URLS.items():
        if "pitcher" in category:
            df = scrape_fangraphs_stats(url, HEADERS['pitcher_headers'])
        else:
            df = scrape_fangraphs_stats(url, HEADERS['team_headers'])
        data_frames[category] = df

    save_dataframes_to_tsv(data_frames)

if __name__ == "__main__":
    main()
